{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ef5e50b0744ee39a99a0623ff97135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"/home/ubuntu/DeepScaleR-1.5B-Preview/\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out how many 'r's are in the word \"Straberry.\" Hmm, let's break this down step by step. First, I should probably write out the word to visualize it better: \"Straberry.\" Now, I'm not very familiar with the spelling of \"Straberry,\" so maybe I should check if I remember correctly. Let me think: S-t-r-a-b-e-r-r-y. Wait, that seems a bit off. Maybe I should just write it out without trying to recall the exact letters. \n",
      "\n",
      "Wait, perhaps it's better to write it down as S T R A B E R R Y. Let me count each 'r' as I go. Starting from the beginning:\n",
      "\n",
      "1. S\n",
      "2. T\n",
      "3. R → that's one 'r'\n",
      "4. A\n",
      "5. B\n",
      "6. E\n",
      "7. R → that's two 'r's\n",
      "8. R\n",
      "9. Y\n",
      "\n",
      "So, in \"Straberry,\" the letters are S, T, R, A, B, E, R, R, Y. Wait, that makes it 8 letters. Now, looking for 'r's: positions 3, 7, 8. So that's three 'r's. But wait, let me count again because sometimes when I write quickly, I might miss.\n",
      "\n",
      "Starting over: S (1), T (2), R (3), A (4), B (5), E (6), R (7), R (8), Y (9). Yes, that's nine letters. So positions 3, 7, and 8 are 'r's. Therefore, there are three 'r's in \"Straberry.\" Wait, but earlier I thought it was three, but maybe I should verify.\n",
      "\n",
      "Alternatively, perhaps the correct spelling is different. Maybe \"Straberry\" is actually \"Straberr\" without the 'y,' but that seems unlikely. Alternatively, perhaps the word is \"Straberry\" without the double 'r's. Maybe I should consider the correct spelling.\n",
      "\n",
      "Wait, perhaps I'm overcomplicating. Let's just go through each letter:\n",
      "\n",
      "1. S\n",
      "2. T\n",
      "3. R → count 1\n",
      "4. A\n",
      "5. B\n",
      "6. E\n",
      "7. R → count 2\n",
      "8. R → count 3\n",
      "9. Y\n",
      "\n",
      "So that's three 'r's. Therefore, the answer should be three.\n",
      "</think>\n",
      "\n",
      "The word \"Straberry\" contains three 'r's. \n",
      "\n",
      "Step-by-step explanation:\n",
      "1. Write out the word: S T R A B E R R Y.\n",
      "2. Identify each 'r':\n",
      "   - Position 3: R\n",
      "   - Position 7: R\n",
      "   - Position 8: R\n",
      "3. Count them: 1, 2, 3.\n",
      "\n",
      "Answer: 3.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How many 'r' in 'Straberry'\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=2048\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
