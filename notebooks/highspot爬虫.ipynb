{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c7c8e8-4690-48ed-b1f4-1336576387a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "class HighspotCrawler:\n",
    "    def __init__(self, cookies: Dict[str, str], headers: Dict[str, str], record_file: str = \"download_record.json\"):\n",
    "        self.cookies = cookies\n",
    "        self.headers = headers\n",
    "        self.base_url = \"https://aws.highspot.com/api/v1\"\n",
    "        self.record_file = record_file\n",
    "        self.record = self._load_record()\n",
    "\n",
    "    def _load_record(self) -> Dict:\n",
    "        \"\"\"Load or initialize the record file\"\"\"\n",
    "        try:\n",
    "            with open(self.record_file, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return {\"file_list\": {}, \"downloaded_files\": {}}\n",
    "\n",
    "    def _save_record(self):\n",
    "        \"\"\"Save the current record to file\"\"\"\n",
    "        with open(self.record_file, \"w\") as f:\n",
    "            json.dump(self.record, f, indent=2)\n",
    "\n",
    "    def _get_file_hash(self, file_info: Dict) -> str:\n",
    "        \"\"\"Generate a hash for file info to detect changes\"\"\"\n",
    "        # Using relevant fields that indicate file changes\n",
    "        key_fields = [\"id\", \"modified\", \"version\"]\n",
    "        hash_content = json.dumps({k: file_info.get(k) for k in key_fields}, sort_keys=True)\n",
    "        return hashlib.md5(hash_content.encode()).hexdigest()\n",
    "\n",
    "    def get_file_list(\n",
    "        self, spot_id: str, incremental: bool = False, limit: int = 25, interval: float = 1.0\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get list of files from a specific spot, handling pagination\n",
    "        With incremental mode support\n",
    "        Args:\n",
    "            spot_id: The ID of the spot to fetch files from\n",
    "            incremental: Whether to use incremental mode\n",
    "            limit: Number of items per request\n",
    "            interval: Time to wait between requests in seconds\n",
    "        \"\"\"\n",
    "        all_items = []\n",
    "        start = 0\n",
    "        page = 1\n",
    "        spot_records = self.record[\"file_list\"].setdefault(spot_id, {})\n",
    "\n",
    "        while True:\n",
    "            print(f\"Fetching page {page}, total files: {len(all_items)}\")\n",
    "            url = f\"{self.base_url}/spots/{spot_id}/items\"\n",
    "            params = {\n",
    "                \"counts\": \"true\",\n",
    "                \"include\": \"lists\",\n",
    "                \"thumbnail\": \"small\",\n",
    "                \"limit\": limit,\n",
    "                \"resolve_links\": \"false\",\n",
    "                \"list\": \"all\",\n",
    "                \"buckets\": \"true\",\n",
    "                \"sortby\": \"time_added\",\n",
    "                \"start\": start,\n",
    "                \"_\": str(int(time.time() * 1000)),\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, params=params, cookies=self.cookies, headers=self.headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            items = response.json()[\"items\"]\n",
    "\n",
    "            if not items:\n",
    "                print(f\"Finished fetching. Total pages: {page-1}, total files: {len(all_items)}\")\n",
    "                break\n",
    "\n",
    "            for item in items:\n",
    "                file_hash = self._get_file_hash(item)\n",
    "                if incremental and item[\"id\"] in spot_records:\n",
    "                    if spot_records[item[\"id\"]][\"hash\"] == file_hash:\n",
    "                        # Found unchanged file in incremental mode, stop fetching\n",
    "                        print(f\"Found unchanged file, stopping. Total pages: {page}, total files: {len(all_items)}\")\n",
    "                        return all_items\n",
    "\n",
    "                # Update record with both hash and complete item data\n",
    "                spot_records[item[\"id\"]] = {\"hash\": file_hash, \"data\": item}\n",
    "                all_items.append(item)\n",
    "\n",
    "            # Save record after processing each batch of items\n",
    "            self._save_record()\n",
    "            start += limit\n",
    "            page += 1\n",
    "\n",
    "            # Add sleep between requests\n",
    "            time.sleep(interval)\n",
    "\n",
    "        return all_items\n",
    "\n",
    "    def get_download_token(self, spot_id: str, item_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Get download token for a specific file\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/spots/{spot_id}/items/{item_id}/download/request_token\"\n",
    "        params = {\"_\": str(int(time.time() * 1000))}\n",
    "\n",
    "        response = requests.get(url, params=params, cookies=self.cookies, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"contentToken\"]\n",
    "\n",
    "    def download_file(self, spot_id: str, item_id: str, output_dir: str, incremental: bool = False) -> Tuple[str, bool]:\n",
    "        \"\"\"\n",
    "        Download a file using its token, with incremental mode support\n",
    "        Returns: (output_path, was_downloaded)\n",
    "        \"\"\"\n",
    "        # Check if file was already downloaded in incremental mode\n",
    "        spot_downloads = self.record[\"downloaded_files\"].setdefault(spot_id, {})\n",
    "        file_info = self.record[\"file_list\"].get(spot_id, {}).get(item_id)\n",
    "        if incremental and item_id in spot_downloads:\n",
    "            if spot_downloads[item_id] == file_info[\"hash\"]:\n",
    "                # File already downloaded and unchanged\n",
    "                return (os.path.join(output_dir, spot_downloads[f\"{item_id}_path\"]), False)\n",
    "        # Get download token first\n",
    "        token = self.get_download_token(spot_id, item_id)\n",
    "\n",
    "        # Use token to download file\n",
    "        download_url = \"https://api.highspot.com/download\"\n",
    "        params = {\"token\": token}\n",
    "\n",
    "        response = requests.get(download_url, params=params, cookies=self.cookies, headers=self.headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Get filename from content name, otherwise use item_id\n",
    "        filename = item_id\n",
    "        if \"contentName\" in file_info[\"data\"]:\n",
    "            filename = file_info[\"data\"][\"contentName\"]\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save file\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # Update download record\n",
    "        spot_downloads[item_id] = file_info[\"hash\"]\n",
    "        spot_downloads[f\"{item_id}_path\"] = filename\n",
    "        self._save_record()\n",
    "\n",
    "        return (output_path, True)\n",
    "\n",
    "    def get_all_saved_files(self, content_types: List[str] = [\"Presentation\", \"PDF\"]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Read and return all saved file information from the record file\n",
    "        Args:\n",
    "            content_types: List of content types to filter by (defaults to ['Presentation', 'PDF'])\n",
    "        Returns: List of file data dictionaries\n",
    "        \"\"\"\n",
    "        all_files = []\n",
    "        for files in self.record[\"file_list\"].values():\n",
    "            files_data = [file_info[\"data\"] for file_info in files.values() if \"data\" in file_info]\n",
    "            if content_types:\n",
    "                files_data = [f for f in files_data if f.get(\"contentType\") in content_types]\n",
    "            all_files.extend(files_data)\n",
    "        return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed7b408-a5ae-46a5-bb4f-2e65d7b0e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = {\n",
    "    'viewer2': 'v2-eyJ1dWlkIjoiNDMxYTAxM2UtMTkwZi00MWYzLTk5YTgtZmYyNGFmMzg1NTBk%0AIn0%3D%0A',\n",
    "    'hs_app': '1',\n",
    "    '_gcl_au': '1.1.1288311553.1737363875',\n",
    "    '__adroll_fpc': '4fa6a1a67f7b059f226f53adaad22ea6-1737363875813',\n",
    "    '_fbp': 'fb.1.1737363876059.8757533326447209',\n",
    "    '_biz_uid': '0ad40fd8e8924341a340450a9f4483b7',\n",
    "    '_biz_nA': '2',\n",
    "    '_biz_flagsA': '%7B%22Version%22%3A1%2C%22ViewThrough%22%3A%221%22%2C%22XDomain%22%3A%221%22%7D',\n",
    "    '_biz_pendingA': '%5B%5D',\n",
    "    '__q_state_JAoFmz9jHzhzN6Qe': 'eyJ1dWlkIjoiYTc1OGVmNTMtN2JjNi00MmIyLWJhZDYtNjg2MjQzZGQwOGVjIiwiY29va2llRG9tYWluIjoiaGlnaHNwb3QuY29tIiwiYWN0aXZlU2Vzc2lvbklkIjpudWxsLCJzdGF0ZUJ5U2NyaXB0SWQiOnsiMTU0NDM0MDI4MjU5NDQ4NDkxMyI6eyJkaXNtaXNzZWQiOmZhbHNlLCJzZXNzaW9uSWQiOm51bGx9fSwibWVzc2VuZ2VyRXhwYW5kZWQiOmZhbHNlLCJwcm9tcHREaXNtaXNzZWQiOmZhbHNlLCJjb252ZXJzYXRpb25JZCI6IjE1NzM2ODIzMDAyNTY1NTk3NTIifQ==',\n",
    "    '_ga': 'GA1.1.1019504351.1737363876',\n",
    "    '_mkto_trk': 'id:623-OHN-043&token:_mch-highspot.com-5265284898d0d65b12cd5462f56f3be',\n",
    "    '_vwo_uuid_v2': 'D205F351421B5E39926B26DBFD458C474|17b03b492ee16dbb74f279a13f1e5129',\n",
    "    '_vis_opt_s': '1%7C',\n",
    "    '_vis_opt_test_cookie': '1',\n",
    "    '_vwo_uuid': 'D205F351421B5E39926B26DBFD458C474',\n",
    "    '_vwo_ds': '3%3Aa_0%2Ct_0%3A0%241737363895%3A99.68909128%3A%3A9_0%2C8_0%2C5_0%2C4_0%2C3_0%2C2_0%3A76_0%2C12_0%2C3_0%2C2_0%3A0',\n",
    "    '_ga_GKWMC1GJF4': 'GS1.1.1737363875.1.1.1737365214.0.0.2144609614',\n",
    "    'rack.session2': 'eyJzZXNzaW9uX2lkIjoiMWE5MzczY2FiNDQwN2EyYWI3NDFlMTAwZDYwMjk3MzQ1NjExZGQ0ZGEzOWYyN2MzM2I2NWM0YjU5NjU3ZDgxYyIsIl9mbGFzaCI6e30sIm51dGVsbGEiOiI1ZjExNTgwMTYyOGJhMjU1M2RmM2UxNjUiLCJzdSI6InN1MCIsInRva2VuIjoiMjo6MTQ2ZGYyNGQtOTc1Ny00NzhhLWJkNTctZGRmZjI2NGJkODJiOjAiLCJjc3JmIjoid3JaakNRV1EySnh2dWpnLTFlWmcwejU2a2p0aUkwQ3FvNGhQaktkdFdRNCJ9--deb5e9f98d8cfa8f13b4e7aa9f7cda1c5c652c83',\n",
    "    '__reveal_ut': 'f1d6aab8-2cea-4de1-576a-e76e6573a03d',\n",
    "    'amp_27c1db': 'aN7IX7YKCySxO8cjiUztaq.ZGJjYWJlYjg5MjMzNTBkOTQxYTk=..1ii958k5t.1ii9593c2.r.o.1j',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "    'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Content-Type': 'application/json',\n",
    "    'HS-CSRF': 'VyS2Se5NQc9mmevoqquiR3L0296HI7ADs2hnPsss0ypR',\n",
    "    'HS-USER-ID': '5f115801628ba2553df3e165',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    #'newrelic': 'eyJ2IjpbMCwxXSwiZCI6eyJ0eSI6IkJyb3dzZXIiLCJhYyI6IjQ1MDM0MSIsImFwIjoiMjU5NDc2OSIsImlkIjoiZTZmN2QwNjViMGQwYjM4OSIsInRyIjoiOGFjOWNiYmJhNWY0ODBhY2U2NTU5ZWE4OGFmNTQxNjEiLCJ0aSI6MTczNzM2Mjk3NDM0MX19',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    #'traceparent': '00-8ac9cbbba5f480ace6559ea88af54161-e6f7d065b0d0b389-01',\n",
    "    #'tracestate': '450341@nr=0-1-450341-2594769-e6f7d065b0d0b389----1737362974341',\n",
    "}\n",
    "\n",
    "crawler = HighspotCrawler(cookies, headers)\n",
    "\n",
    "# Example usage\n",
    "spot_id = \"60bdbd9634d6be4dbd9ce328\"\n",
    "output_dir = \"downloads\"\n",
    "incremental = True  # Set to False for full download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1be91e-fee8-40d9-b6a1-c1d0dcc8f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file list\n",
    "files = crawler.get_all_saved_files()\n",
    "# Get file list\n",
    "#files = crawler.get_file_list(spot_id, incremental=incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8313c-8597-4087-b2e6-38f481ebda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download each file\n",
    "from tqdm import tqdm\n",
    "for file in tqdm(files):\n",
    "    try:\n",
    "        output_path, was_downloaded = crawler.download_file(\n",
    "            spot_id, file[\"id\"], output_dir, incremental=incremental\n",
    "        )\n",
    "        if was_downloaded:\n",
    "            print(f\"Downloaded: {output_path}\")\n",
    "        else:\n",
    "            print(f\"Skipped unchanged file: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {file['id']}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d4f9b0b-7e0f-41b9-a3a6-77af4ef6e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_list = glob.glob('pdf/*.pdf')\n",
    "for row in file_list:\n",
    "    if row[4:] in mapping1:\n",
    "        sample = {\n",
    "              \"metadataAttributes\": {\n",
    "                \"x-amz-bedrock-kb-source-uri\": {\n",
    "                  \"value\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"stringValue\": f\"https://aws.highspot.com/items/{mapping1[row[4:]]}\"\n",
    "                  },\n",
    "                  \"includeForEmbedding\": True\n",
    "                },\n",
    "                \"updated_date\": {\n",
    "                  \"value\": {\n",
    "                    \"type\": \"NUMBER\",\n",
    "                    \"numberValue\": 20240205\n",
    "                  },\n",
    "                  \"includeForEmbedding\": True\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "        json.dump(sample, open(row+'.metadata.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
